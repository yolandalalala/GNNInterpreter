{
 "cells": [
  {
   "cell_type": "code",
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T14:55:36.937389Z",
     "start_time": "2024-04-21T14:55:36.923878Z"
    }
   },
   "id": "8c2caaab483d0a24",
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "from gnninterpreter import *"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T14:56:11.218284Z",
     "start_time": "2024-04-21T14:55:38.181890Z"
    }
   },
   "id": "97e983f9da03809c",
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from tqdm.auto import trange"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T14:56:11.245402Z",
     "start_time": "2024-04-21T14:56:11.219994Z"
    }
   },
   "id": "8afbbc605bb13730",
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Cyclicity"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb003ff51143b6cf"
  },
  {
   "cell_type": "code",
   "source": [
    "cyclicity = CyclicityDataset(seed=12345)\n",
    "cyclicity_train, cyclicity_val = cyclicity.train_test_split(k=10)\n",
    "cyclicity_model = NNConvClassifier(node_features=len(cyclicity.NODE_CLS),\n",
    "                                   edge_features=len(cyclicity.EDGE_CLS),\n",
    "                                   num_classes=len(cyclicity.GRAPH_CLS),\n",
    "                                   hidden_channels=32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T01:01:01.422612Z",
     "start_time": "2024-04-16T01:00:58.703590Z"
    }
   },
   "id": "f9ca8d33db768581",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T01:01:25.297269Z",
     "start_time": "2024-04-16T01:01:25.214256Z"
    }
   },
   "cell_type": "code",
   "source": "cyclicity_model.load_state_dict(torch.load('ckpts/cyclicity.pt'))",
   "id": "6184b0a0e815cd4d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "for epoch in trange(128):\n",
    "    train_loss = cyclicity_train.model_fit(motif_model, lr=0.001)\n",
    "    train_metrics = cyclicity_train.model_evaluate(motif_model)\n",
    "    val_metrics = cyclicity_val.model_evaluate(motif_model)\n",
    "    print(f\"Epoch: {epoch:03d}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, \"\n",
    "          f\"Train Acc: {train_metrics['acc']:.4f}, \"\n",
    "          f\"Test Acc: {val_metrics['acc']:.4f}, \"\n",
    "          f\"Train F1: {train_metrics['f1']}, \"\n",
    "          f\"Test F1: {val_metrics['f1']}\")"
   ],
   "id": "5d04071033ea9eb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "# torch.save(cyclicity_model.state_dict(), 'ckpts/cyclicity.pt')",
   "id": "a3e9dfc10e55569f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Motif"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2364be7c0ee37620"
  },
  {
   "cell_type": "code",
   "source": [
    "motif = MotifDataset(seed=12345)\n",
    "motif_train, motif_val = motif.train_test_split(k=10)\n",
    "motif_model = GCNClassifier(node_features=len(motif.NODE_CLS),\n",
    "                            num_classes=len(motif.GRAPH_CLS),\n",
    "                            hidden_channels=64,\n",
    "                            num_layers=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T14:56:14.918140Z",
     "start_time": "2024-04-21T14:56:11.246383Z"
    }
   },
   "id": "85a99f52ad4d19a3",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-21T14:58:18.712652Z",
     "start_time": "2024-04-21T14:58:18.668171Z"
    }
   },
   "cell_type": "code",
   "source": "motif_model.load_state_dict(torch.load('ckpts/motif.pt'))",
   "id": "3ac90580b55bd488",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in range(128):\n",
    "    train_loss = motif_train.model_fit(motif_model, lr=0.001)\n",
    "    train_metrics = motif_train.model_evaluate(motif_model)\n",
    "    val_metrics = motif_val.model_evaluate(motif_model)\n",
    "    print(f\"Epoch: {epoch:03d}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, \"\n",
    "          f\"Train Acc: {train_metrics['acc']:.4f}, \"\n",
    "          f\"Test Acc: {val_metrics['acc']:.4f}, \"\n",
    "          f\"Train F1: {train_metrics['f1']}, \"\n",
    "          f\"Test F1: {val_metrics['f1']}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T15:01:18.681716Z",
     "start_time": "2024-04-21T14:59:20.749584Z"
    }
   },
   "id": "77849acc80fe593e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 000, Train Loss: 0.0158, Train Acc: 0.9965, Test Acc: 0.9905, Train F1: {'partial': 0.9913957715034485, 'house': 0.9992445111274719, 'house_x': 0.9963099360466003, 'comp_4': 0.9965269565582275, 'comp_5': 0.9992886185646057}, Test F1: {'partial': 0.9755011200904846, 'house': 0.9978213310241699, 'house_x': 0.9912663698196411, 'comp_4': 0.9894291758537292, 'comp_5': 0.9978586435317993}\n",
      "Epoch: 001, Train Loss: 0.0255, Train Acc: 0.9999, Test Acc: 0.9957, Train F1: {'partial': 0.9997596740722656, 'house': 1.0, 'house_x': 1.0, 'comp_4': 0.9997692108154297, 'comp_5': 1.0}, Test F1: {'partial': 0.9887640476226807, 'house': 0.9978213310241699, 'house_x': 1.0, 'comp_4': 0.9915611743927002, 'comp_5': 1.0}\n",
      "Epoch: 002, Train Loss: 0.0159, Train Acc: 0.9976, Test Acc: 0.9948, Train F1: {'partial': 0.993959903717041, 'house': 0.9992441534996033, 'house_x': 0.9997548460960388, 'comp_4': 0.9965509176254272, 'comp_5': 0.9985781908035278}, Test F1: {'partial': 0.9863636493682861, 'house': 0.9978213310241699, 'house_x': 1.0, 'comp_4': 0.9937106966972351, 'comp_5': 0.995726466178894}\n",
      "Epoch: 003, Train Loss: 0.0267, Train Acc: 0.9465, Test Acc: 0.9488, Train F1: {'partial': 0.890556275844574, 'house': 0.9898374080657959, 'house_x': 0.9135692119598389, 'comp_4': 0.9772266149520874, 'comp_5': 0.9605327844619751}, Test F1: {'partial': 0.8905109763145447, 'house': 0.9867841601371765, 'house_x': 0.9203187227249146, 'comp_4': 0.9753086566925049, 'comp_5': 0.9668874144554138}\n",
      "Epoch: 004, Train Loss: 0.0168, Train Acc: 0.9979, Test Acc: 0.9931, Train F1: {'partial': 0.9946834444999695, 'house': 0.9984902143478394, 'house_x': 0.9985315799713135, 'comp_4': 0.9976979494094849, 'comp_5': 1.0}, Test F1: {'partial': 0.9817351698875427, 'house': 0.9956521987915039, 'house_x': 1.0, 'comp_4': 0.987500011920929, 'comp_5': 1.0}\n",
      "Epoch: 005, Train Loss: 0.0119, Train Acc: 0.9948, Test Acc: 0.9853, Train F1: {'partial': 0.9870503544807434, 'house': 0.9918699264526367, 'house_x': 0.9970674514770508, 'comp_4': 0.9976979494094849, 'comp_5': 1.0}, Test F1: {'partial': 0.9623059630393982, 'house': 0.9753915071487427, 'house_x': 0.9935483932495117, 'comp_4': 0.9937106966972351, 'comp_5': 1.0}\n",
      "Epoch: 006, Train Loss: 0.0142, Train Acc: 0.9993, Test Acc: 0.9957, Train F1: {'partial': 0.9983152747154236, 'house': 0.9989929795265198, 'house_x': 1.0, 'comp_4': 0.9993079304695129, 'comp_5': 1.0}, Test F1: {'partial': 0.9887133240699768, 'house': 0.9978213310241699, 'house_x': 1.0, 'comp_4': 0.9915966391563416, 'comp_5': 1.0}\n",
      "Epoch: 007, Train Loss: 0.0231, Train Acc: 0.9992, Test Acc: 0.9948, Train F1: {'partial': 0.9980732202529907, 'house': 0.9997480511665344, 'house_x': 1.0, 'comp_4': 0.9983874559402466, 'comp_5': 1.0}, Test F1: {'partial': 0.9864253401756287, 'house': 0.9978213310241699, 'house_x': 1.0, 'comp_4': 0.9895178079605103, 'comp_5': 1.0}\n",
      "Epoch: 008, Train Loss: 0.0148, Train Acc: 0.9992, Test Acc: 0.9948, Train F1: {'partial': 0.9980741739273071, 'house': 0.9997479319572449, 'house_x': 1.0, 'comp_4': 0.9983874559402466, 'comp_5': 1.0}, Test F1: {'partial': 0.9863636493682861, 'house': 0.9978213310241699, 'house_x': 1.0, 'comp_4': 0.9895615577697754, 'comp_5': 1.0}\n",
      "Epoch: 009, Train Loss: 0.0142, Train Acc: 0.9985, Test Acc: 0.9931, Train F1: {'partial': 0.9961389899253845, 'house': 1.0, 'house_x': 1.0, 'comp_4': 0.9976979494094849, 'comp_5': 0.9985781908035278}, Test F1: {'partial': 0.9819004535675049, 'house': 0.9934354424476624, 'house_x': 1.0, 'comp_4': 0.991631805896759, 'comp_5': 0.9978586435317993}\n",
      "Epoch: 010, Train Loss: 0.0084, Train Acc: 0.9954, Test Acc: 0.9913, Train F1: {'partial': 0.9883325099945068, 'house': 0.9949849843978882, 'house_x': 1.0, 'comp_4': 0.9938087463378906, 'comp_5': 0.9997626543045044}, Test F1: {'partial': 0.9770641922950745, 'house': 0.9934924244880676, 'house_x': 1.0, 'comp_4': 0.9854469895362854, 'comp_5': 1.0}\n",
      "Epoch: 011, Train Loss: 0.0109, Train Acc: 0.9994, Test Acc: 0.9948, Train F1: {'partial': 0.998555600643158, 'house': 0.9997480511665344, 'house_x': 1.0, 'comp_4': 0.9988476634025574, 'comp_5': 1.0}, Test F1: {'partial': 0.9864253401756287, 'house': 0.9978213310241699, 'house_x': 1.0, 'comp_4': 0.9895178079605103, 'comp_5': 1.0}\n",
      "Epoch: 012, Train Loss: 0.0117, Train Acc: 0.9981, Test Acc: 0.9948, Train F1: {'partial': 0.9951691031455994, 'house': 0.9997480511665344, 'house_x': 1.0, 'comp_4': 0.9956352114677429, 'comp_5': 1.0}, Test F1: {'partial': 0.9863636493682861, 'house': 0.9978213310241699, 'house_x': 1.0, 'comp_4': 0.9895615577697754, 'comp_5': 1.0}\n",
      "Epoch: 013, Train Loss: 0.0204, Train Acc: 0.9897, Test Acc: 0.9879, Train F1: {'partial': 0.9748767018318176, 'house': 0.9989929795265198, 'house_x': 1.0, 'comp_4': 0.9756558537483215, 'comp_5': 1.0}, Test F1: {'partial': 0.969298243522644, 'house': 0.9978213310241699, 'house_x': 0.9978308081626892, 'comp_4': 0.9741379022598267, 'comp_5': 1.0}\n",
      "Epoch: 014, Train Loss: 0.0157, Train Acc: 0.9986, Test Acc: 0.9922, Train F1: {'partial': 0.9963916540145874, 'house': 0.9979879260063171, 'house_x': 1.0, 'comp_4': 0.9983829855918884, 'comp_5': 1.0}, Test F1: {'partial': 0.9797753095626831, 'house': 0.9956521987915039, 'house_x': 0.9978308081626892, 'comp_4': 0.9873417615890503, 'comp_5': 1.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m128\u001B[39m):\n\u001B[0;32m----> 2\u001B[0m     train_loss \u001B[38;5;241m=\u001B[39m \u001B[43mmotif_train\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmotif_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlr\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.001\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m     train_metrics \u001B[38;5;241m=\u001B[39m motif_train\u001B[38;5;241m.\u001B[39mmodel_evaluate(motif_model)\n\u001B[1;32m      4\u001B[0m     val_metrics \u001B[38;5;241m=\u001B[39m motif_val\u001B[38;5;241m.\u001B[39mmodel_evaluate(motif_model)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/gnninterpreter/lib/python3.10/site-packages/gnn_xai_common/datasets/base_graph_dataset.py:146\u001B[0m, in \u001B[0;36mBaseGraphDataset.model_fit\u001B[0;34m(self, model, batch_size, lr)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m batch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloader(batch_size\u001B[38;5;241m=\u001B[39mbatch_size, shuffle\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[1;32m    145\u001B[0m     model\u001B[38;5;241m.\u001B[39mzero_grad()  \u001B[38;5;66;03m# Clear gradients.\u001B[39;00m\n\u001B[0;32m--> 146\u001B[0m     out \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Perform a single forward pass.\u001B[39;00m\n\u001B[1;32m    147\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(out[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mlogits\u001B[39m\u001B[38;5;124m'\u001B[39m], batch\u001B[38;5;241m.\u001B[39my)  \u001B[38;5;66;03m# Compute the loss.\u001B[39;00m\n\u001B[1;32m    148\u001B[0m     loss\u001B[38;5;241m.\u001B[39mbackward()  \u001B[38;5;66;03m# Derive gradients.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/gnninterpreter/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/gnninterpreter/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/gnninterpreter/lib/python3.10/site-packages/gnn_xai_common/models/gcn_classifier.py:30\u001B[0m, in \u001B[0;36mGCNClassifier.forward\u001B[0;34m(self, batch, embeds, embeds_last, edge_weight, temperature)\u001B[0m\n\u001B[1;32m     24\u001B[0m node_weight \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m edge_weight \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     25\u001B[0m                \u001B[38;5;28;01melse\u001B[39;00m smooth_maximum_weight_propagation(batch\u001B[38;5;241m.\u001B[39medge_index, edge_weight,\n\u001B[1;32m     26\u001B[0m                                                       size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mlen\u001B[39m(batch\u001B[38;5;241m.\u001B[39mx),\n\u001B[1;32m     27\u001B[0m                                                       temperature\u001B[38;5;241m=\u001B[39mtemperature))\n\u001B[1;32m     29\u001B[0m \u001B[38;5;66;03m# 1. Obtain node embeddings\u001B[39;00m\n\u001B[0;32m---> 30\u001B[0m h \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mbatch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     32\u001B[0m \u001B[38;5;66;03m# 2. Readout layer\u001B[39;00m\n\u001B[1;32m     33\u001B[0m embeds \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mcat([\n\u001B[1;32m     34\u001B[0m     global_sum_pool_weighted(h, batch\u001B[38;5;241m=\u001B[39mbatch\u001B[38;5;241m.\u001B[39mbatch, node_weight\u001B[38;5;241m=\u001B[39mnode_weight),\n\u001B[1;32m     35\u001B[0m     global_mean_pool_weighted(h, batch\u001B[38;5;241m=\u001B[39mbatch\u001B[38;5;241m.\u001B[39mbatch, node_weight\u001B[38;5;241m=\u001B[39mnode_weight),\n\u001B[1;32m     36\u001B[0m ], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/gnninterpreter/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/gnninterpreter/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/gnninterpreter/lib/python3.10/site-packages/torch_geometric/nn/models/basic_gnn.py:252\u001B[0m, in \u001B[0;36mBasicGNN.forward\u001B[0;34m(self, x, edge_index, edge_weight, edge_attr, batch, batch_size, num_sampled_nodes_per_hop, num_sampled_edges_per_hop)\u001B[0m\n\u001B[1;32m    249\u001B[0m     x \u001B[38;5;241m=\u001B[39m conv(x, edge_index, edge_weight\u001B[38;5;241m=\u001B[39medge_weight,\n\u001B[1;32m    250\u001B[0m              edge_attr\u001B[38;5;241m=\u001B[39medge_attr)\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupports_edge_weight:\n\u001B[0;32m--> 252\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[43mconv\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43medge_weight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_weight\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    253\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupports_edge_attr:\n\u001B[1;32m    254\u001B[0m     x \u001B[38;5;241m=\u001B[39m conv(x, edge_index, edge_attr\u001B[38;5;241m=\u001B[39medge_attr)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/gnninterpreter/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/gnninterpreter/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/gnninterpreter/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:260\u001B[0m, in \u001B[0;36mGCNConv.forward\u001B[0;34m(self, x, edge_index, edge_weight)\u001B[0m\n\u001B[1;32m    257\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    258\u001B[0m             edge_index \u001B[38;5;241m=\u001B[39m cache\n\u001B[0;32m--> 260\u001B[0m x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;66;03m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001B[39;00m\n\u001B[1;32m    263\u001B[0m out \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpropagate(edge_index, x\u001B[38;5;241m=\u001B[39mx, edge_weight\u001B[38;5;241m=\u001B[39medge_weight)\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/gnninterpreter/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[1;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/gnninterpreter/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[0;32m/opt/homebrew/Caskroom/mambaforge/base/envs/gnninterpreter/lib/python3.10/site-packages/torch_geometric/nn/dense/linear.py:147\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, x)\u001B[0m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[1;32m    142\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"Forward pass.\u001B[39;00m\n\u001B[1;32m    143\u001B[0m \n\u001B[1;32m    144\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[1;32m    145\u001B[0m \u001B[38;5;124;03m        x (torch.Tensor): The input features.\u001B[39;00m\n\u001B[1;32m    146\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 147\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(motif_model.state_dict(), 'ckpts/motif.pt')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-21T15:01:21.416283Z",
     "start_time": "2024-04-21T15:01:21.383349Z"
    }
   },
   "id": "b2a5adde85f03d0a",
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": [
    "# MUTAG"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "7fbdf852d5323bb9"
  },
  {
   "cell_type": "code",
   "source": [
    "mutag = MUTAGDataset(seed=12345)\n",
    "mutag_train, mutag_val = mutag.train_test_split(k=10)\n",
    "mutag_model = GCNClassifier(node_features=len(mutag.NODE_CLS),\n",
    "                            num_classes=len(mutag.GRAPH_CLS),\n",
    "                            hidden_channels=64,\n",
    "                            num_layers=3)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T01:02:06.135934Z",
     "start_time": "2024-04-16T01:02:06.081495Z"
    }
   },
   "id": "a0688406c7338df1",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T01:03:19.018968Z",
     "start_time": "2024-04-16T01:03:18.991633Z"
    }
   },
   "cell_type": "code",
   "source": "mutag_model.load_state_dict(torch.load('ckpts/mutag.pt'))",
   "id": "e7c48954c7e99593",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in trange(128):\n",
    "    train_loss = mutag_train.model_fit(motif_model, lr=0.001)\n",
    "    train_metrics = mutag_train.model_evaluate(motif_model)\n",
    "    val_metrics = mutag_val.model_evaluate(motif_model)\n",
    "    print(f\"Epoch: {epoch:03d}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, \"\n",
    "          f\"Train Acc: {train_metrics['acc']:.4f}, \"\n",
    "          f\"Test Acc: {val_metrics['acc']:.4f}, \"\n",
    "          f\"Train F1: {train_metrics['f1']}, \"\n",
    "          f\"Test F1: {val_metrics['f1']}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "55ec64e3c68d4b1e",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "torch.save(mutag_model.state_dict(), 'ckpts/mutag.pt')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6a5ab4dbfdc5fa6d",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Shape"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c08571a9c4869c96"
  },
  {
   "cell_type": "code",
   "source": [
    "shape = ShapeDataset(seed=12345)\n",
    "shape_train, shape_val = shape.train_test_split(k=10)\n",
    "shape_model = GCNClassifier(node_features=len(shape.NODE_CLS),\n",
    "                            num_classes=len(shape.GRAPH_CLS),\n",
    "                            hidden_channels=64,\n",
    "                            num_layers=4)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-16T01:03:23.996496Z",
     "start_time": "2024-04-16T01:03:22.986013Z"
    }
   },
   "id": "209fa2b252805ab2",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T01:03:25.121485Z",
     "start_time": "2024-04-16T01:03:25.056630Z"
    }
   },
   "cell_type": "code",
   "source": "shape_model.load_state_dict(torch.load('ckpts/shape.pt'))",
   "id": "f2ada6701ace2f2d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "for epoch in range(128):\n",
    "    train_loss = shape_train.model_fit(motif_model, lr=0.001)\n",
    "    train_metrics = shape_train.model_evaluate(motif_model)\n",
    "    val_metrics = shape_val.model_evaluate(motif_model)\n",
    "    print(f\"Epoch: {epoch:03d}, \"\n",
    "          f\"Train Loss: {train_loss:.4f}, \"\n",
    "          f\"Train Acc: {train_metrics['acc']:.4f}, \"\n",
    "          f\"Test Acc: {val_metrics['acc']:.4f}, \"\n",
    "          f\"Train F1: {train_metrics['f1']}, \"\n",
    "          f\"Test F1: {val_metrics['f1']}\")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1cfd9312b4bdc4d9",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": "torch.save(shape_model.state_dict(), 'ckpts/shape_overfitting.pt')",
   "metadata": {
    "collapsed": false
   },
   "id": "326dfb91cb8fba96",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "75b6d2b5b5eb7a65",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
